---  
layout: post  
title: "Code Week"  
tags: [bibliographic annotation, fieldbook]  
author: Meg Szydlik 
---

The idea of literacy is such a fascinating one, because the goalposts for it have dramatically changed thoughout the years. Bear with me, I promise this will all link together. In the early days of America, literacy rates were actually quite high, but not that many people could write their own name, which to us today seems like a fairly basic component of literacy, but the truth is that people were taught how to read but not how to write. So you had a surprisingly high number of early Americans who could actually read Thomas Paine, but who couldn't sign a land deed. We think of reading and writing as inexorably linked, but that's actually a very new concept. Unfortunately, its a lot harder to figure out who could read than who could write, since any material record requires the ability to write. I would argue that the same kind of thing is happening with programming and coding. We can use programs and interfaces, apply algorithms and tell the computer what to do. In essence, we can "read" the final product. What we cannot do, is create product ourselves. That's a different skill, the same way writing requires different brain and muscle use than reading does. Additionally, just because I can read the individual words on the page of, say, *Jane Eyre*, doesn't mean I actually understand them and it certainly doesn't mean that I can interpret them the way a scholar of 19th century gothic novels can. In fact, I know that my relationship with the book is different from that of an English scholar. There's nothing inherently wrong with that! It just means that the word literacy means different things to different people, and understanding the contexts of the word is essential for understanding the rest of the argument.

That is definitely true of how digital humanities use algorithms and computational analysis. I confess I have a complex relationship with things like text analysis. It is my firm and unyielding view that when you break a book down to its component parts, you lose it. It can be incredibly useful to do so! Knowing what words appear most (and least) frequently can bend your understanding of a work and its themes, for example. However, like everything, it belongs in its proper context. An program that collects the most common words in *The Little Princess*, the book I looked at during last week's lab, is only valuable if I already know the story. Last semester I ran a topic modeling program on the letters in the Jane Addams Papers Project, and what I found was interesting but only because I was already very familiar with the collection. If I was not, then the categories would have been a lot harder to crack and identify and be able to connect to the wider history around Jane Addams and the Progressive movement. When you "over-science" the humanities, you lose what makes it tick. We talk all the time in my program about striking the very complicated balance between what the data tells you and what the history and communities tell you. Data and algorithms are perfectly likely to be corrupted or incomplete and knowing that, if the data seriously contradicts all of its context, it is worth asking why. (I also think that humanists, including plenty of these writers, have an overly divine sense of what scientists do, but my friends who are scientists are constantly interpreting data and redoing experiments and looking at other people's work and **judging** other people's work because it does still come from a position of bias and interpretation. They don't think data springs from nowhere either, their discipline just has a less flexible element to it, though racism was scientific there for a hot second and so was astrology and its weird cousin numerology.) Of course, it is perfectly possible that new examinations and manipulations of data can produce new understandings of historical or literary texts, but it is far more likely to simply be a new way to bend the text(s)...and that's fine. Having a balance of understanding the benefits of looking at this data differently, of using different tools on the same content, and keeping everything in the context of the actual text and the history around it. 